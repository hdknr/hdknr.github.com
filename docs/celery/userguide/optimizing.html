

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Optimizing &mdash; Celery 1 documentation</title>
    
    <link rel="stylesheet" href="../static/haiku.css" type="text/css" />
    <link rel="stylesheet" href="../static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../static/print.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../static/jquery.js"></script>
    <script type="text/javascript" src="../static/underscore.js"></script>
    <script type="text/javascript" src="../static/doctools.js"></script>
    <script type="text/javascript" src="../static/theme_extras.js"></script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="top" title="Celery 1 documentation" href="../index.html" />
    <link rel="up" title="User Guide" href="index.html" />
    <link rel="next" title="Concurrency" href="concurrency/index.html" />
    <link rel="prev" title="Security" href="security.html" /> 
  </head>
  <body>
      <div class="header"><h1 class="heading"><a href="../index.html">
          <span>Celery 1 documentation</span></a></h1>
        <h2 class="heading"><span>Optimizing</span></h2>
      </div>
      <div class="topnav">
      
        <p>
        <a href="/">Home</a>:
        «&#160;&#160;<a href="security.html">Security</a>
        &#160;&#160;::&#160;&#160;
        <a class="uplink" href="../index.html">Contents</a>
        &#160;&#160;::&#160;&#160;
        <a href="concurrency/index.html">Concurrency</a>&#160;&#160;»
        </p>

      </div>
      <div class="content">
        
        
  <div class="section" id="optimizing">
<span id="guide-optimizing"></span><h1>Optimizing<a class="headerlink" href="#optimizing" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>The default configuration makes a lot of compromises.  It&#8217;s not optimal for
any single case, but works well enough for most situations.</p>
<p>There are optimizations that can be applied based on specific use cases.</p>
<p>Optimizations can apply to different properties of the running environment,
be it the time tasks take to execute, the amount of memory used, or
responsiveness at times of high load.</p>
</div>
<div class="section" id="ensuring-operations">
<h2>Ensuring Operations<a class="headerlink" href="#ensuring-operations" title="Permalink to this headline">¶</a></h2>
<p>In the book <a class="reference external" href="http://www.cs.bell-labs.com/cm/cs/pearls/">Programming Pearls</a>, Jon Bentley presents the concept of
back-of-the-envelope calculations by asking the question;</p>
<blockquote>
<div>❝ How much water flows out of the Mississippi River in a day? ❞</div></blockquote>
<p>The point of this exercise[*] is to show that there is a limit
to how much data a system can process in a timely manner.
Back of the envelope calculations can be used as a means to plan for this
ahead of time.</p>
<p>In Celery; If a task takes 10 minutes to complete,
and there are 10 new tasks coming in every minute, the queue will never
be empty.  This is why it&#8217;s very important
that you monitor queue lengths!</p>
<p>A way to do this is by <a class="reference internal" href="monitoring.html#monitoring-munin"><em>using Munin</em></a>.
You should set up alerts, that will notify you as soon as any queue has
reached an unacceptable size.  This way you can take appropriate action
like adding new worker nodes, or revoking unnecessary tasks.</p>
<table class="docutils footnote" frame="void" id="id1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[*]</td><td>The chapter is available to read for free here:
<a class="reference external" href="http://books.google.com/books?id=kse_7qbWbjsC&amp;pg=PA67">The back of the envelope</a>.  The book is a classic text. Highly
recommended.</td></tr>
</tbody>
</table>
</div>
<div class="section" id="general-settings">
<span id="optimizing-general-settings"></span><h2>General Settings<a class="headerlink" href="#general-settings" title="Permalink to this headline">¶</a></h2>
<div class="section" id="librabbitmq">
<span id="optimizing-librabbitmq"></span><h3>librabbitmq<a class="headerlink" href="#librabbitmq" title="Permalink to this headline">¶</a></h3>
<p>If you&#8217;re using RabbitMQ (AMQP) as the broker then you can install the
<tt class="xref py py-mod docutils literal"><span class="pre">librabbitmq</span></tt> module to use an optimized client written in C:</p>
<div class="highlight-bash"><div class="highlight"><pre><span class="nv">$ </span>pip install librabbitmq
</pre></div>
</div>
<p>The &#8216;amqp&#8217; transport will automatically use the librabbitmq module if it&#8217;s
installed, or you can also specify the transport you want directly by using
the <tt class="docutils literal"><span class="pre">amqplib://</span></tt> or <tt class="docutils literal"><span class="pre">librabbitmq://</span></tt> prefixes.</p>
</div>
<div class="section" id="broker-connection-pools">
<span id="optimizing-connection-pools"></span><h3>Broker Connection Pools<a class="headerlink" href="#broker-connection-pools" title="Permalink to this headline">¶</a></h3>
<p>The broker connection pool is enabled by default since version 2.5.</p>
<p>You can tweak the <a class="reference internal" href="../configuration.html#std:setting-BROKER_POOL_LIMIT"><tt class="xref std std-setting docutils literal"><span class="pre">BROKER_POOL_LIMIT</span></tt></a> setting to minimize
contention, and the value should be based on the number of
active threads/greenthreads using broker connections.</p>
</div>
</div>
<div class="section" id="worker-settings">
<span id="optimizing-worker-settings"></span><h2>Worker Settings<a class="headerlink" href="#worker-settings" title="Permalink to this headline">¶</a></h2>
<div class="section" id="prefetch-limits">
<span id="optimizing-prefetch-limit"></span><h3>Prefetch Limits<a class="headerlink" href="#prefetch-limits" title="Permalink to this headline">¶</a></h3>
<p><em>Prefetch</em> is a term inherited from AMQP that is often misunderstood
by users.</p>
<p>The prefetch limit is a <strong>limit</strong> for the number of tasks (messages) a worker
can reserve for itself.  If it is zero, the worker will keep
consuming messages, not respecting that there may be other
available worker nodes that may be able to process them sooner[#],
or that the messages may not even fit in memory.</p>
<p>The workers&#8217; default prefetch count is the
<a class="reference internal" href="../configuration.html#std:setting-CELERYD_PREFETCH_MULTIPLIER"><tt class="xref std std-setting docutils literal"><span class="pre">CELERYD_PREFETCH_MULTIPLIER</span></tt></a> setting multiplied by the number
of child worker processes[#].</p>
<p>If you have many tasks with a long duration you want
the multiplier value to be 1, which means it will only reserve one
task per worker process at a time.</p>
<p>However &#8211; If you have many short-running tasks, and throughput/round trip
latency[#] is important to you, this number should be large. The worker is
able to process more tasks per second if the messages have already been
prefetched, and is available in memory.  You may have to experiment to find
the best value that works for you.  Values like 50 or 150 might make sense in
these circumstances. Say 64, or 128.</p>
<p>If you have a combination of long- and short-running tasks, the best option
is to use two worker nodes that are configured separately, and route
the tasks according to the run-time. (see <a class="reference internal" href="routing.html#guide-routing"><em>Routing Tasks</em></a>).</p>
<table class="docutils footnote" frame="void" id="id2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[†]</td><td>RabbitMQ and other brokers deliver messages round-robin,
so this doesn&#8217;t apply to an active system.  If there is no prefetch
limit and you restart the cluster, there will be timing delays between
nodes starting. If there are 3 offline nodes and one active node,
all messages will be delivered to the active node.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[‡]</td><td>This is the concurrency setting; <a class="reference internal" href="../configuration.html#std:setting-CELERYD_CONCURRENCY"><tt class="xref std std-setting docutils literal"><span class="pre">CELERYD_CONCURRENCY</span></tt></a> or the
<em class="xref std std-option">-c</em> option to <strong class="program">celeryd</strong>.</td></tr>
</tbody>
</table>
</div>
<div class="section" id="reserve-one-task-at-a-time">
<h3>Reserve one task at a time<a class="headerlink" href="#reserve-one-task-at-a-time" title="Permalink to this headline">¶</a></h3>
<p>When using early acknowledgement (default), a prefetch multiplier of 1
means the worker will reserve at most one extra task for every active
worker process.</p>
<p>When users ask if it&#8217;s possible to disable &#8220;prefetching of tasks&#8221;, often
what they really want is to have a worker only reserve as many tasks as there
are child processes.</p>
<p>But this is not possible without enabling late acknowledgements
acknowledgements; A task that has been started, will be
retried if the worker crashes mid execution so the task must be <a class="reference external" href="http://en.wikipedia.org/wiki/Idempotent">idempotent</a>
(see also notes at <a class="reference internal" href="../faq.html#faq-acks-late-vs-retry"><em>Should I use retry or acks_late?</em></a>).</p>
<p>You can enable this behavior by using the following configuration options:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">CELERY_ACKS_LATE</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">CELERYD_PREFETCH_MULTIPLIER</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="section" id="rate-limits">
<h3>Rate Limits<a class="headerlink" href="#rate-limits" title="Permalink to this headline">¶</a></h3>
<p>The system responsible for enforcing rate limits introduces some overhead,
so if you&#8217;re not using rate limits it may be a good idea to
disable them completely.  This will disable one thread, and it won&#8217;t
spend as many CPU cycles when the queue is inactive.</p>
<p>Set the <a class="reference internal" href="../configuration.html#std:setting-CELERY_DISABLE_RATE_LIMITS"><tt class="xref std std-setting docutils literal"><span class="pre">CELERY_DISABLE_RATE_LIMITS</span></tt></a> setting to disable
the rate limit subsystem:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">CELERY_DISABLE_RATE_LIMITS</span> <span class="o">=</span> <span class="bp">True</span>
</pre></div>
</div>
</div>
</div>
</div>


      </div>
      <div class="bottomnav">
      
        <p>
        <a href="/">Home</a>:
        «&#160;&#160;<a href="security.html">Security</a>
        &#160;&#160;::&#160;&#160;
        <a class="uplink" href="../index.html">Contents</a>
        &#160;&#160;::&#160;&#160;
        <a href="concurrency/index.html">Concurrency</a>&#160;&#160;»
        </p>

      </div>

    <div class="footer">
        &copy; Copyright 2012, HDKNR.COM.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.2pre/3c28de26aac2.
    </div>
  </body>
</html>